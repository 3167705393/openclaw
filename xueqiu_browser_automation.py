#!/usr/bin/env python3
"""
é›ªçƒæµè§ˆå™¨è‡ªåŠ¨åŒ–è·å–å™¨
ä½¿ç”¨Playwrightæµè§ˆå™¨è‡ªåŠ¨åŒ–è·å–é›ªçƒå¸–å­å†…å®¹
"""

from playwright.sync_api import sync_playwright
import time
import re
from datetime import datetime
from typing import List, Dict

class XueqiuBrowserAutomation:
    def __init__(self, u_value: str, xq_a_token: str):
        self.u_value = u_value
        self.xq_a_token = xq_a_token
        
    def get_posts(self, max_posts: int = 10) -> List[Dict]:
        """
        è·å–é›ªçƒå¸–å­
        """
        posts = []
        
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True, args=[
                '--no-sandbox', 
                '--disable-setuid-sandbox',
                '--disable-dev-shm-usage'
            ])
            page = browser.new_page()
            
            # è®¾ç½®è¯·æ±‚å¤´
            page.set_extra_http_headers({
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            })
            
            # è®¾ç½®cookies
            cookies = [
                {'name': 'u', 'value': self.u_value, 'domain': '.xueqiu.com', 'path': '/'},
                {'name': 'xq_a_token', 'value': self.xq_a_token, 'domain': '.xueqiu.com', 'path': '/'}
            ]
            
            page.context.add_cookies(cookies)
            
            try:
                print(f"[{datetime.now().strftime('%H:%M:%S')}] è®¿é—®é›ªçƒé¦–é¡µ...")
                page.goto('https://xueqiu.com/', timeout=15000)
                
                # ç­‰å¾…é¡µé¢åŠ è½½
                page.wait_for_timeout(3000)
                
                # æŸ¥æ‰¾å¸–å­å…ƒç´ 
                print(f"[{datetime.now().strftime('%H:%M:%S')}] æŸ¥æ‰¾å¸–å­å…ƒç´ ...")
                
                # å°è¯•å¤šç§é€‰æ‹©å™¨
                selectors = ['article', 'div.feed-item', 'div.status-item', 'div.stream-item']
                
                posts_elements = []
                for selector in selectors:
                    try:
                        elements = page.query_selector_all(selector)
                        if elements and len(elements) > 0:
                            posts_elements = elements
                            print(f"   - ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(elements)} ä¸ªå¸–å­")
                            break
                    except:
                        continue
                
                if not posts_elements:
                    print("   - æœªæ‰¾åˆ°å¸–å­å…ƒç´ ï¼Œå°è¯•é€šç”¨é€‰æ‹©å™¨")
                    posts_elements = page.query_selector_all('div[class*=\"feed\" i], div[class*=\"status\" i], div[class*=\"post\" i]')
                
                print(f"[{datetime.now().strftime('%H:%M:%S')}] è§£æ {len(posts_elements)} ä¸ªå¸–å­...")
                
                for i, element in enumerate(posts_elements[:max_posts]):
                    try:
                        # è·å–å®Œæ•´çš„å¸–å­æ–‡æœ¬å†…å®¹
                        full_text = element.inner_text()
                        
                        if not full_text or len(full_text.strip()) < 20:
                            continue  # è·³è¿‡å†…å®¹å¤ªå°‘çš„å…ƒç´ 
                        
                        # è§£æå¸–å­å†…å®¹
                        parsed_post = self._parse_post(full_text)
                        
                        if parsed_post:
                            parsed_post['index'] = i + 1
                            posts.append(parsed_post)
                            
                    except Exception as e:
                        print(f"   - è§£æå¸–å­ {i+1} æ—¶å‡ºé”™: {e}")
                        continue
                        
            except Exception as e:
                print(f"âŒ æµè§ˆå™¨è‡ªåŠ¨åŒ–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
            
            finally:
                browser.close()
        
        return posts
    
    def _parse_post(self, full_text: str) -> Dict:
        """
        è§£æå¸–å­æ–‡æœ¬å†…å®¹
        """
        lines = full_text.split('\n')
        lines = [line.strip() for line in lines if line.strip()]
        
        # åˆå§‹åŒ–å¸–å­å†…å®¹
        post = {
            'title': 'æ— æ ‡é¢˜',
            'author': 'æœªçŸ¥ä½œè€…',
            'content': '',
            'time_info': '',
            'interactions': ''
        }
        
        # å°è¯•è¯†åˆ«å„ä¸ªéƒ¨åˆ†
        author_patterns = [
            r'.*?ä¿®æ”¹äº.*',  # åŒ…å«"ä¿®æ”¹äº"çš„è¡Œ
            r'.*?Â·\s*æ¥è‡ª.*',  # åŒ…å«"Â· æ¥è‡ª"çš„è¡Œ
            r'.*?\d{1,2}:\d{2}.*',  # åŒ…å«æ—¶é—´çš„è¡Œ
            r'.*?\d{1,2}-\d{1,2}.*'  # åŒ…å«æ—¥æœŸçš„è¡Œ
        ]
        
        content_lines = []
        author_line = ''
        
        for line in lines:
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä½œè€…ä¿¡æ¯è¡Œ
            is_author = False
            for pattern in author_patterns:
                if re.search(pattern, line):
                    author_line = line
                    is_author = True
                    break
            
            # å¦‚æœä¸æ˜¯ä½œè€…ä¿¡æ¯ï¼Œä¹Ÿä¸æ˜¯çŸ­æ ‡é¢˜è¡Œï¼Œåˆ™è®¤ä¸ºæ˜¯å†…å®¹
            if not is_author and len(line) > 20:
                content_lines.append(line)
        
        # è®¾ç½®ä½œè€…
        if author_line:
            post['author'] = author_line
        
        # è®¾ç½®å†…å®¹
        if content_lines:
            post['content'] = ' '.join(content_lines[:5])  # å–å‰5è¡Œå†…å®¹
        
        # å°è¯•ä»å†…å®¹ä¸­æå–æ ‡é¢˜ï¼ˆè¾ƒçŸ­çš„æœ‰æ„ä¹‰è¡Œï¼‰
        for line in lines:
            if 10 < len(line) < 100 and not re.search(r'Â·\s*æ¥è‡ª|ä¿®æ”¹äº|\d{1,2}:\d{2}', line):
                post['title'] = line
                break
        
        # é™åˆ¶å†…å®¹é•¿åº¦
        if len(post['content']) > 500:
            post['content'] = post['content'][:500] + '...'
        
        return post
    
    def display_posts(self, posts: List[Dict]):
        """
        æ˜¾ç¤ºå¸–å­å†…å®¹
        """
        if not posts:
            print("âŒ æœªè·å–åˆ°ä»»ä½•å¸–å­")
            return
        
        print(f"\nğŸ“Š è·å–åˆ° {len(posts)} ä¸ªå¸–å­:")
        print("="*80)
        
        for post in posts:
            print(f"\nğŸ“ˆ å¸–å­ {post['index']}:")
            print(f"ğŸ“ æ ‡é¢˜: {post['title']}")
            print(f"ğŸ‘¤ ä½œè€…: {post['author']}")
            print(f"ğŸ“„ å†…å®¹: {post['content']}")
            print("-" * 60)

def main():
    print("ğŸ¯ é›ªçƒæµè§ˆå™¨è‡ªåŠ¨åŒ–è·å–å™¨")
    print("="*80)
    
    # ä½¿ç”¨æä¾›çš„å‡­è¯
    automation = XueqiuBrowserAutomation(
        u_value="8603655584",
        xq_a_token="17fa2787f256c2057245b461d0c6085a10db6eef"
    )
    
    print("ğŸš€ å¼€å§‹è·å–é›ªçƒå¸–å­...")
    
    # è·å–å¸–å­
    posts = automation.get_posts(max_posts=10)
    
    # æ˜¾ç¤ºç»“æœ
    automation.display_posts(posts)
    
    print(f"\nâœ… ä»»åŠ¡å®Œæˆï¼Œå…±è·å– {len(posts)} ä¸ªå¸–å­")

if __name__ == "__main__":
    main()