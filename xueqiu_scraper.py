#!/usr/bin/env python3
"""
é›ªçƒå¸–å­çˆ¬å–å™¨
ç”¨äºè·å–å®Œæ•´çš„å¸–å­å†…å®¹
"""

import requests
import json
import time
from typing import Dict, List, Optional
from urllib.parse import urlencode

class XueqiuScraper:
    def __init__(self, cookies: Optional[Dict] = None):
        """
        åˆå§‹åŒ–é›ªçƒçˆ¬å–å™¨
        :param cookies: ç™»å½•åçš„cookiesï¼Œç”¨äºè®¿é—®éœ€è¦ç™»å½•çš„å†…å®¹
        """
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Referer': 'https://xueqiu.com/',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8'
        })
        
        if cookies:
            self.session.cookies.update(cookies)
    
    def search_topics(self, query: str, count: int = 10) -> List[Dict]:
        """
        æœç´¢è¯é¢˜
        """
        search_url = "https://xueqiu.com/statuses/search.json"
        params = {
            'q': query,
            'count': count,
            'page': 1
        }
        
        try:
            response = self.session.get(search_url, params=params)
            response.raise_for_status()
            data = response.json()
            
            # æå–å¸–å­ä¿¡æ¯
            statuses = data.get('statuses', [])
            posts = []
            
            for status in statuses:
                post = {
                    'id': status.get('id'),
                    'user': status.get('user', {}).get('screen_name'),
                    'title': status.get('title', ''),
                    'description': status.get('description', ''),
                    'text': status.get('text', ''),
                    'created_at': status.get('created_at'),
                    'like_count': status.get('like_count', 0),
                    'comment_count': status.get('comment_count', 0),
                    'retweet_count': status.get('retweet_count', 0),
                    'href': f"https://xueqiu.com{status.get('target', '')}"
                }
                posts.append(post)
            
            return posts
        except Exception as e:
            print(f"æœç´¢å¤±è´¥: {e}")
            return []
    
    def get_post_detail(self, post_id: str) -> Dict:
        """
        è·å–å•ä¸ªå¸–å­çš„è¯¦ç»†å†…å®¹
        """
        detail_url = f"https://xueqiu.com/statuses/original/show.json"
        params = {'id': post_id}
        
        try:
            response = self.session.get(detail_url, params=params)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"è·å–å¸–å­è¯¦æƒ…å¤±è´¥: {e}")
            return {}
    
    def get_user_posts(self, user_id: str, count: int = 20) -> List[Dict]:
        """
        è·å–ç‰¹å®šç”¨æˆ·çš„å¸–å­
        """
        user_url = f"https://xueqiu.com/v4/statuses/user_timeline.json"
        params = {
            'user_id': user_id,
            'page': 1,
            'count': count
        }
        
        try:
            response = self.session.get(user_url, params=params)
            response.raise_for_status()
            data = response.json()
            
            statuses = data.get('statuses', [])
            posts = []
            
            for status in statuses:
                post = {
                    'id': status.get('id'),
                    'user': status.get('user', {}).get('screen_name'),
                    'title': status.get('title', ''),
                    'text': status.get('text', ''),
                    'created_at': status.get('created_at'),
                    'like_count': status.get('like_count', 0),
                    'comment_count': status.get('comment_count', 0),
                    'retweet_count': status.get('retweet_count', 0),
                    'href': f"https://xueqiu.com{status.get('target', '')}"
                }
                posts.append(post)
            
            return posts
        except Exception as e:
            print(f"è·å–ç”¨æˆ·å¸–å­å¤±è´¥: {e}")
            return []

def demo_xueqiu_scraper():
    """
    æ¼”ç¤ºé›ªçƒçˆ¬å–å™¨åŠŸèƒ½
    """
    print("ğŸ¯ é›ªçƒå¸–å­çˆ¬å–å™¨æ¼”ç¤º")
    print("="*60)
    print("âš ï¸  æ³¨æ„ï¼šè¦è·å–å®Œæ•´å¸–å­å†…å®¹ï¼Œéœ€è¦ç™»å½•å‡­è¯ï¼ˆcookiesï¼‰")
    print("ğŸ’¡  è¯·æä¾›é›ªçƒç™»å½•åçš„cookiesï¼Œä»¥è·å–éœ€è¦ç™»å½•æ‰èƒ½æŸ¥çœ‹çš„å†…å®¹")
    print("="*60)
    
    # æ¨¡æ‹Ÿå±•ç¤ºåŠŸèƒ½ï¼Œä¸å®é™…è®¿é—®
    print("\nğŸ“‹ å¯ç”¨åŠŸèƒ½ï¼š")
    print("  1. search_topics(query) - æœç´¢è¯é¢˜")
    print("  2. get_post_detail(post_id) - è·å–å¸–å­è¯¦æƒ…") 
    print("  3. get_user_posts(user_id) - è·å–ç”¨æˆ·å¸–å­")
    
    print("\nğŸ” ä½¿ç”¨æ–¹æ³•ï¼š")
    print("  scraper = XueqiuScraper(cookies={'xueqiu_auth_token': 'your_token'})")
    print("  posts = scraper.search_topics('çƒ­é—¨è¯é¢˜')")
    
    print("\nğŸ’¡ å¦‚æœæ‚¨æä¾›ç™»å½•å‡­è¯ï¼Œæˆ‘å¯ä»¥è·å–å®Œæ•´çš„å¸–å­å†…å®¹ã€‚")

if __name__ == "__main__":
    demo_xueqiu_scraper()